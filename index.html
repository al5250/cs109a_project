<!DOCTYPE html>
<!--[if lt IE 8 ]><html class="no-js ie ie7" lang="en"> <![endif]-->
<!--[if IE 8 ]><html class="no-js ie ie8" lang="en"> <![endif]-->
<!--[if IE 9 ]><html class="no-js ie ie9" lang="en"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><!--><html class="no-js" lang="en"> <!--<![endif]-->
<head>

   <!--- Basic Page Needs
   ================================================== -->
   <meta charset="utf-8">
	<title>CS109a Anomaly Detection</title>
	<meta name="description" content="">
	<meta name="author" content="">

   <!-- Mobile Specific Metas
   ================================================== -->
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<!-- CSS
    ================================================== -->
   <link rel="stylesheet" href="css/base.css">
	<link rel="stylesheet" href="css/main.css">
   <link rel="stylesheet" href="css/media-queries.css">

   <!-- Script
   =================================================== -->
	<script src="js/modernizr.js"></script>

</head>

<body class="homepage">

   <div id="preloader">
	   <div id="status">
         <img src="images/loader.gif" height="60" width="60" alt="">
         <div class="loader">Loading...</div>
      </div>
   </div>


   <!-- Header
   =================================================== -->
   <header id="main-header">

   	<div class="row header-inner">

	      <nav id="nav-wrap">

	         <a class="mobile-btn" href="#nav-wrap" title="Show navigation">
	         	<span class='menu-text'>Show Menu</span>
	         	<span class="menu-icon"></span>
	         </a>
         	<a class="mobile-btn" href="#" title="Hide navigation">
         		<span class='menu-text'>Hide Menu</span>
         		<span class="menu-icon"></span>
         	</a>

	         <ul id="nav" class="nav">
	            <li class="current"><a class="smoothscroll" href="#hero">Home.</a></li>
		         <li><a class="smoothscroll" href="#method">Method.</a></li>
	            <li><a class="smoothscroll" href="#results">Results.</a></li>
              <li><a class="smoothscroll" href="#conclusions">Conclusions.</a></li>
                <li><a href="https://github.com/al5250/cs109a_project" target="_blank">Github.</a></li>
	         </ul>

	      </nav> <!-- /nav-wrap -->

	   </div> <!-- /header-inner -->

   </header>


   <!-- Hero
   =================================================== -->
   <section id="hero">

		<div class="row hero-content">

			<div class="twelve columns flex-container">

			   <div id="hero-slider" class="flexslider">

				   <ul class="slides">

					   <li>
						   <div class="flex-caption">
								<h1>Anomaly Detection in Time Series</h1>
                                <h2>Created for CS109a by Alex Lin and Melissa Yu</h2>
								<p><a class="button stroke " href="https://github.com/al5250/cs109a_project/archive/master.zip" target="_blank">Download Source Code</a></p>
							</div>
					   </li>

				   </ul>

			   </div> <!-- .flexslider -->

	      </div> <!-- .flex-container -->

		</div> <!-- .hero-content -->

   </section> <!-- #hero -->


   <!-- Method Section
   ================================================== -->
   <section id="method">

      <div class="row section-head">

           <div class="twelve columns">

               <h1>Method<span>.</span></h1>

               <hr />

           </div>

       </div>

      <div class="row about-content">

      	<div class="mob-whole twelve columns">

      		<h2>1. Asking the Question.</h2>

            <h3>Problem Statement</h3>
	      	<p>
                Given a sequence of random variables, we wish to develop a method
                for determining the existence of anomalies.
	        </p>
            <p>
                Specifically, as the variables arrive one by one, we test the exchangeability assumption for
                the sequence, which states that the joint distribution for these variables is invariant under
                any permutation of the indices. One method for anomaly detection involves using a Martingale,
                a sequence of random variables such that the expectation of a variable is equal to the value of
                the variable at the last point in time. In particular, the martingale here models the degree to which
                the data violates the null hypothesis given by the exchangeability assumption.
            </p>

            <h3>Key Questions</h3>
            <ul>
                <li>How can we appropriately construct Martingales that will successfully
                detect the existence of different kinds of anomalous data?</li>
                <li>What is the best Martingale threshold level for rejecting the null hypothesis?</li>
                <li>Is there a tradeoff between the accuracy and the confidence of our methods?</li>
            </ul>


      	</div>

      	<div class="mob-whole twelve columns">

	      	<h2>2. Getting the Data.</h2>

            <h3>Anomaly Types</h3>
	      	<p>Our study focuses on three general types of anomalies.</p>
            <img src="images/anomaly_types.png" alt="Anomaly Types">

	      	<p>
                We construct various datasets with these three structures to evaluate the efficacy of our methods.
                We also examine real-life time series datasets from Twitter giving counts for the number of Tweet
                mentions of large, publicly-trade companies (e.g. AAPL, AMZN, CVS, FB) over five-minute intervals.
	        </p>

      	</div>

        <div class="mob-whole twelve columns">

      		<h2>3. Standardizing the Algorithm.</h2>

	      	<p>
                Here is our generalized, two-step procedure for analyzing a dataset,
                constructing Martingales, and detecting anomalies. We wrap all of
                our methods in an AnomalyDetector class, whose objects can be instantiated
                with two main customizable options – (1) a strangeness function and (2)
                a Martingale construction method.
	        </p>

            <h3>Part One</h3>
	      	<p>Importing the training examples one by one and generating a list of corresponding p-values.</p>
            <img src="images/part1.png" alt="Part 1">

            <h3>Part Two</h3>
	      	<p>Constructing a Martingale from the sequence of p-values</p>
            <img src="images/part2.png" alt="Part 2">

            <p>
                This general algorithm was first introduced by Vovk et al. in [1].
                In this project, we add our own customizations to answer the specific
                questions we posed.
            </p>

      	</div>

      </div>

   </section>


   <!-- Results Section
   ================================================== -->
   <section id="results">

       <div class="row section-head">

            <div class="twelve columns">

                <h1>Results<span>.</span></h1>

                <hr />

            </div>

        </div>

       <div class="row about-content">

         <div class="mob-whole twelve columns">

             <h2>1. Evaluating Strangeness Functions.</h2>

             <h3>A First Experiment</h3>
             <p>
                 We compare the relative efficacy of different strangeness functions
                 for Part One of the algorithm in generating Martingales.
             </p>
             <ul>
                 <li>Each dataset is self-constructed, contains 110 data points and
                     2 ‘change points’ that signify the onset of an anomaly.</li>
                 <li>For this part of the analysis, we standardize Part Two of the
                     algorithm by using a power method with a fixed betting function
                     and epsilon 0.8</li>
             </ul>

             <p>
                 Here are the four different strangeness functions we examine.
             </p>
             <img src="images/stranges.png" alt="Strangeness Functions">

             <h3>Non-Anomalous Data</h3>
             <p>
                We first test to see how the four strangeness functions perform on non-anomalous data, as a control for our experiment.  The data is simply a time series in which each point comes from the Norm(0, 1) distribution.  Ideally, we want the generated Martingales to be small in value.  Here is the generated data:
             </p>

             <img src="img/graphs/figure_6.png" alt="Data1" width="40%">

             <p>
                These four graphs chart the performance of the strangeness functions, tracking the respective Martingale values over time.  Note that in this case, the values all get smaller over time, which leads the algorithm to not identify any anomalies.  This is exactly what we want.
             </p>

             <img src="img/graphs/figure_7.png" alt="Data1" width="40%">
             <img src="img/graphs/figure_8.png" alt="Data1" width="40%">
             <img src="img/graphs/figure_9.png" alt="Data1" width="40%">
             <img src="img/graphs/figure_10.png" alt="Data1" width="40%">

             <p>
                We now look at how the strangeness functions perform on anomalous data.
             </p>


             <h3>Anomaly Type #1: Random Outliers</h3>

             <p>
                Here is a graph of our self-generated time series data containing the random outlier anomaly.  The 'change points' are denoted by dashed red lines:
             </p>

             <img src="img/graphs/figure_1.png" alt="Data1" width="40%">

              <p>
                These are plots of the Martingales produced by the four different strangeness functions for the above dataset:
             </p>

             <img src="img/graphs/figure_2.png" alt="Data1" width="40%">
             <img src="img/graphs/figure_3.png" alt="Data1" width="40%">
             <img src="img/graphs/figure_4.png" alt="Data1" width="40%">
             <img src="img/graphs/figure_5.png" alt="Data1" width="40%">

             <p>
                All four strangeness functions produce Martingales that locally peak right after an outlier occurs in the time series data.  However, due to the fact that there are very few outliers, these peaks for Average Distance, Range Percentile, and OLS Trend are not actually high enough to be global maximums, which is undesirable.  Instead, we see that <b>OLS Residual</b> performs the best, which is expected since the difference between a random outliers’ expected value and its predicted value should be significantly large.
             </p>

             <h3>Anomaly Type #2: Sudden Gap</h3>

             <p>
                Here is a graph of our self-generated time series data containing the sudden gap anomaly.  The 'change points' are denoted by dashed red lines:
             </p>


             <img src="img/graphs/figure_16.png" alt="Data1" width="40%">

              <p>
                These are plots of the Martingales produced by the four different strangeness functions for the above dataset:
             </p>

             <img src="img/graphs/figure_17.png" alt="Data1" width="40%">
             <img src="img/graphs/figure_18.png" alt="Data1" width="40%">
             <img src="img/graphs/figure_19.png" alt="Data1" width="40%">
             <img src="img/graphs/figure_20.png" alt="Data1" width="40%">

             <p>
                All four methods seem to perform well for this type of anomaly; they all have peak Martingales after the appearance of a gap. Note that <b> Average Distance </b> produces the highest-valued Martingale.   
             </p>

             <h3>Anomaly Type #3: Slope Change</h3>

             <p>
                Here is a graph of our self-generated time series data containing the slope change anomaly.  The 'change points' are denoted by dashed red lines:
             </p>

             <img src="img/graphs/figure_11.png" alt="Data1" width="40%">

              <p>
                These are plots of the Martingales produced by the four different strangeness functions for the above dataset:
             </p>

             <img src="img/graphs/figure_12.png" alt="Data1" width="40%">
             <img src="img/graphs/figure_13.png" alt="Data1" width="40%">
             <img src="img/graphs/figure_14.png" alt="Data1" width="40%">
             <img src="img/graphs/figure_15.png" alt="Data1" width="40%">

             <p>
                Average Distance and Range Percentile perform poorly, as they start increasing before the slope changes.  <b>OLS Trend</b> seems to most accurately reflects the patterns of the slope changes, which is understandable given that this metric measures slope fluctuations. 
              </p>   
         </div>

         <div class="mob-whole twelve columns">

             <h2>2. Comparing Different Thresholds.</h2>

             <h3>Methodology</h3>

             <p>
                We evaluate the efficacy of anomaly detection for different Martingale thresholds.  We expect there to be a tradeoff between the accuracy and the confidence of our methods.  Here are some general points:
             </p>

             <img src="images/method2.png">

             <h3>Graphs</h3>

             <p>
                These are the resultant graphs for each of the three anomaly types.
             </p>

             <img src="img/thresholds/figure_1.png" alt="Data1" width="33%">
             <img src="img/thresholds/figure_2.png" alt="Data1" width="33%">
             <img src="img/thresholds/figure_3.png" alt="Data1" width="33%">

             <p>
                As expected, the results from plotting the accuracies for the anomalous and non-anomalous data for various values of the threshold show that there is a tradeoff between accurately detecting anomalies and classifying “normal” data as non-anomalous. 

                <ul>
                 <li>Setting the threshold value too low will result in very high accuracies for anomalous data, since nearly all data streams will be labeled as violating the exchangeability condition, but the tradeoff is that non-anomalous data streams will be mistakenly classified as anomalous too.</li>
                 <li>Note that the Slope Change data run with the OLS Trend strangeness function shows that nearly all threshold values produce ~100% accuracy on non-anomalous data. We expect this given that previous results show that OLS Trend for non-anomalous data almost monotonically drops from 0.</li>
                 <li>Optimal threshold can be chosen by considering which of the 2 accuracies (anomalous and non-anomalous) is more important to the user/application at hand.</li>
                </ul>
             </p>



         </div>

         <div class="mob-whole twelve columns">

             <h2>3. Real-life Datasets: Twitter Data.</h2>
             <p>
                Finally, we test the algorithm on a real-life dataset from Twitter.  We obtained our time series data from <a href="https://github.com/numenta/NAB/tree/master/data/realTweets">this link</a>.  Each dataset corresponds to a count of the number of Twitter mentions of large, publicly-traded companies over an interval of 5 minutes. Each row in a dataset contains a timestamp for when the 5-minute interval starts and the corresponding counts for the associated company.  The specific dataset we look at is for Amazon (AMZN).  This is the time series, with the dashed red line denoting the start of the anomaly (as indicated by the collectors):
             </p>

             <img src="img/twitter_results/figure_1.png" alt="Data1" width="40%">

             <p>
                Note that it exhibits a Random Outliers structure.  Thus, we chose to use the OLS Residual strangeness function for the Martingale-based anomaly detection algorithm.  The results are below:
             </p>

             <img src="img/twitter_results/figure_2.png" alt="Data1" width="40%">

             <p>
                Our algorithm performs reasonably well; in particular, it is able to capture the presence of some sort of anomaly via a sudden peak in Martingales around the 2000-second point.  However, note that the Martingale never reaches a value that is larger than the starting value; we conjecture that this may be because too much time passed before we reached the beginning of the anomalous data.  We expect the algorithm to perform better on data that has anomalies towards the beginning of the time series.     
             </p>

         </div>

       </div>

   </section>

   <section id="conclusions">

        <div class="row section-head">

            <div class="twelve columns">

                <h1>Conclusions<span>.</span></h1>

                <hr />

            </div>

        </div>

        <div class="row about-content">

         <div class="mob-whole twelve columns">

             <h3>Main Concepts</h3>

             <p>
             <ul>
                 <li>Choose Strangeness Function Based on Data: Different strangeness functions are better suited to detecting different anomaly types.</li>
                 <li>Choose Threshold Based on User Priorities: There is a tradeoff between detecting anomalies accurately and classifying non-anomalous data streams correctly. Choose a threshold based on the user’s priorities.</li>
              </ul>
            
             </p>

             <h3>Future Work</h3>

             <p>
             <ul>
                 <li>Explore performance of various strangeness functions for labeled data (1-Nearest Neighbor, SVM, Decision Trees) since our current work focuses only on unlabeled data streams.</li>
                 <li>Evaluate performance of current methods on multidimensional datasets and make improvements as necessary.</li>
                 <li>Explore other martingale construction methods, including Sleepy Jumper, etc.</li>
                <li>After hitting a change point, remove previous points from memory to improve accuracy of detecting future anomalies.</li>
              </ul>
            
             </p>

             <h3>References</h3>

             <p>
             <ol>
                 <li>Vovk, V., Nouretdinov, I., and Gammerman, A. Testing exchangeability on-line. In Proceedings of the 20th International Conference on Machine Learning, pp. 768–775, 2003.</li>
                 <li>Ho, S.-S. A martingale framework for concept change detection in time-varying data streams. In Proceedings of the 22nd International Conference on Machine Learning, pp. 321–327, 2005.</li>
                 <li>Fedorova et. al. Plug-in martingales for testing exchangeability on-line. In Proceedings of the 29th International Conference on Machine Learning.</li>
              </ol>
            
             </p>

             <h3>Appendix: Code</h3>

             <p>
             All of our code can be downloaded from the GitHub link above.  Here are descriptions of our main code files:
             <ul>
                 <li>anomaly_detector.py - the main anomaly detection class that implements the anomaly detection algorithm with two main customizable features: strangeness function and Martingale generation process </li>
                 <li>betting.py - a module of different betting functions for Martingale generation</li>
                 <li>gen_data.py - a module that generates anomalous data based on the three main types (random outlier, sudden gap, slope change)</li>
                 <li>martingale.py - a module of different processes for Martingale generation</li>
                 <li>strange.py - a module of different strangeness functions for part 1 of the anomaly detection algorithm</li>
              </ul>
              Here are descriptions of the scripts used to obtain our results:
              <ul>
                <li>classify_twitter_data.py - a script for running our anomaly detection algorithm on the AMZN Twitter data; detailed in Part 3 of the Results section</li>
                <li>classify_twitter_data.py - a script for running our anomaly detection algorithm with different strangeness functions on different anomaly types; detailed in Part 1 of the Results section</li>
                <li>threshold_tuning.py - a script for trying different thresholds for our anomaly detection algorithm for different anomaly types; detailed in Part 2 of the Results section</li>
              </ul>
            
             </p>
          </div>

        </div>

   </section>


   <!-- Footer
   ================================================== -->
   <footer>

      <div class="row">

         <p class="copyright">&copy; Copyright 2014 Puremedia. Design by <a href="http://www.styleshout.com/">Styleshout.</a></p>

         <div id="go-top">
            <a class="smoothscroll" title="Back to Top" href="#hero"><span>Top</span><i class="fa fa-long-arrow-up"></i></a>
         </div>

      </div> <!-- /row -->

   </footer> <!-- /footer -->


   <!-- Java Script
   ================================================== -->
   <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
   <script>window.jQuery || document.write('<script src="js/jquery-1.10.2.min.js"><\/script>')</script>
   <script type="text/javascript" src="js/jquery-migrate-1.2.1.min.js"></script>
   <script src="js/jquery.flexslider.js"></script>
   <script src="js/jquery.fittext.js"></script>
   <script src="js/backstretch.js"></script>
   <script src="js/waypoints.js"></script>
   <script src="js/main.js"></script>

</body>

</html>
