{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy.stats import mode\n",
    "from sklearn import linear_model\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import discriminant_analysis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Directories and file names for raw and processed data\n",
    "RESULTS_DIR = '../data/processed/'\n",
    "TRAIN_RFILE, TEST_RFILE = RESULTS_DIR+'new_trainData.csv', RESULTS_DIR+'new_testData.csv'\n",
    "\n",
    "DATA_DIR = '../data/raw/2008/'\n",
    "TRAIN_FILES = ['0101']\n",
    "# TEST_FILES = ['0710', '0725', '0810', '0825', '0910', '0923',\n",
    "#               '1010', '1025', '1110', '1125', '1210', '1225']\n",
    "TEST_FILES = ['0102']\n",
    "\n",
    "# Constants relating to the dataset\n",
    "LABEL_COL = 17\n",
    "CATEGORICAL_COLS = {13: ['S0', 'S1', 'SF', 'REJ', 'S2', 'S3', 'RSTO',\n",
    "                         'RSTR', 'RSTOS0', 'RSTRH', 'SH', 'SHR', 'OTH'],\n",
    "                    17: [-1, 1]}\n",
    "NUMERIC_COLS = [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 23]\n",
    "USE_COLS = sorted(NUMERIC_COLS+list(CATEGORICAL_COLS.keys()))\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function that preprocesses and saves training/testing data to seperate files.\n",
    "    :return: void\n",
    "    \"\"\"\n",
    "    preprocess(map(create_source_fpath, TRAIN_FILES), TRAIN_RFILE)\n",
    "    preprocess(map(create_source_fpath, TEST_FILES), TEST_RFILE)\n",
    "\n",
    "\n",
    "def encode_categorical(mat):\n",
    "    \"\"\"\n",
    "    One hot encodes categorical features.\n",
    "    :param mat: numpy matrix of shape [n_examples, n_features+1]\n",
    "    :return: (X, y) where X is a numpy matrix of encoded feature vectors\n",
    "        and y is numpy vector of labels corresponding to rows of X\n",
    "    \"\"\"\n",
    "    # encode categorical columns as ints\n",
    "    numeric_indices = [i for i in range(len(USE_COLS)) if USE_COLS[i] in NUMERIC_COLS]\n",
    "    categorical_indices = []\n",
    "\n",
    "    for col, values in CATEGORICAL_COLS.items():\n",
    "        i = USE_COLS.index(col)\n",
    "        if col != LABEL_COL:\n",
    "            categorical_indices.append(i)\n",
    "\n",
    "        # classes = np.unique(mat[:, i])\n",
    "        # if len(np.intersect1d(classes, values)) < len(classes):\n",
    "        #     diff = np.setdiff1d(classes, values)\n",
    "        #     raise ValueError(\"Column {} contains new labels: {}\".format(i, str(diff)))\n",
    "        #\n",
    "        # mat[:, i] = np.array([values.index(e) for e in mat[:, i]])\n",
    "\n",
    "    # extract X and y\n",
    "    (label_index, ) = set(range(len(USE_COLS))) - set(numeric_indices + categorical_indices)\n",
    "    categorical_indices = list(map(lambda i: i-1 if i > label_index else i, categorical_indices))\n",
    "    X, y = np.delete(mat, label_index, 1), mat[:, label_index]\n",
    "\n",
    "    # one hot encode X\n",
    "    # enc = OneHotEncoder(sparse=False, n_values=len(CATEGORICAL_COLS[13]),\n",
    "    #                     categorical_features=categorical_indices)\n",
    "    # X = enc.fit_transform(X)\n",
    "\n",
    "    return X, y.reshape((-1, 1))\n",
    "\n",
    "\n",
    "def preprocess(filepaths, results_file, use_binary_classification=True):\n",
    "    \"\"\"\n",
    "    Takes a list of data files, preprocesses them (one hot encoding, removal of absolute duplicates),\n",
    "    and saves the results to a file. Overwrites previous results file if it exists.\n",
    "\n",
    "    :param filepaths: list of full filenames to process\n",
    "    :param results_file: full filename for storing results\n",
    "    :param use_binary_classification: boolean indicating whether known and unknown attacks should be combined\n",
    "    :return: void\n",
    "    \"\"\"\n",
    "    kwargs = dict(header=False, float_format='%.4f', index=False)\n",
    "\n",
    "    if os.path.isfile(results_file):\n",
    "        os.remove(results_file)\n",
    "\n",
    "    for filepath in filepaths:\n",
    "        df = pd.read_csv(filepath_or_buffer=filepath,\n",
    "                         usecols=USE_COLS,\n",
    "                         delim_whitespace=True,\n",
    "                         header=None)\n",
    "        cleaned_df = df.drop_duplicates()\n",
    "\n",
    "        if use_binary_classification:\n",
    "            bin_labels = cleaned_df.loc[:, LABEL_COL].replace({-2: -1})\n",
    "            cleaned_df.loc[:, LABEL_COL] = bin_labels\n",
    "\n",
    "        # print('class instance counts: \\n{}'.format(cleaned_df.loc[:, self.LABEL_COL].value_counts()))\n",
    "        mat = np.hstack(encode_categorical(cleaned_df.values))\n",
    "\n",
    "        # shuffle data\n",
    "        mat = shuffle(mat, random_state=0)\n",
    "\n",
    "        # save to file\n",
    "        df =pd.concat([\n",
    "            pd.DataFrame(data=mat.astype(float)[:,:11]),\n",
    "            pd.DataFrame(data=mat.astype('|S10')[:,11]),\n",
    "            pd.DataFrame(data=mat.astype(float)[:, 11:])\n",
    "            ], axis=1)\n",
    "        if os.path.isfile(results_file):\n",
    "            df.to_csv(results_file, mode='a', **kwargs)\n",
    "        else:\n",
    "            df.to_csv(results_file, **kwargs)\n",
    "\n",
    "\n",
    "def create_source_fpath(filenum):\n",
    "    return DATA_DIR + '2008' + filenum + '.txt'\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('processing data...')\n",
    "    start_time = time.time()\n",
    "    main()\n",
    "    total_time = time.time() - start_time\n",
    "    print('finished writing data to \\'{}\\' and \\'{}\\' in {} seconds'.format(TRAIN_RFILE, TEST_RFILE, total_time))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
